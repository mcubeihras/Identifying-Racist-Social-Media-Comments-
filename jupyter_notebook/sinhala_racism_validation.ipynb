{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running in Google Colaboratory\n",
    "# If you are running in local ignore this.\n",
    "# Authenticate user and create folder \"sinhala_racism_detection\" to save results\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "parent_dir = '/content/gdrive/My Drive/sinhala_racism_detection'\n",
    "if not os.path.exists(parent_dir):\n",
    "    os.makedirs(parent_dir)\n",
    "\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_last_results_folder():\n",
    "    \"\"\"\n",
    "    Return last created results directory\n",
    "    :return: last created results directory\n",
    "    \"\"\"\n",
    "    result_no = 0\n",
    "    directory = \"results_%d\" % result_no\n",
    "\n",
    "    while os.path.exists(directory):\n",
    "        result_no += 1\n",
    "        directory = \"results_%d\" % result_no\n",
    "\n",
    "    return \"results_%d\" % (result_no - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "def prediction(n: float, r: float, s: float) -> int:\n",
    "    \"\"\"\n",
    "    Returns label of the class with maximum probability\n",
    "    :param n: probability of being Neutral\n",
    "    :param r: probability of being Racist\n",
    "    :param s: probability of being Sexism\n",
    "    :return: label of the class with maximum probability\n",
    "    \"\"\"\n",
    "    lst = [n, r, s]\n",
    "    maximum = max(lst)\n",
    "    max_index = lst.index(maximum)\n",
    "\n",
    "    return [0, 1, 2][max_index]\n",
    "\n",
    "\n",
    "def build_confusion_matrix(result_file_name: str, confusion_matrix_file_name: str) -> list:\n",
    "    \"\"\"\n",
    "    calculate confusion matrix and save to disk\n",
    "    :param result_file_name: result file to read\n",
    "    :param confusion_matrix_file_name: file name to save the confusion matrix\n",
    "    :return: confusion matrix\n",
    "    \"\"\"\n",
    "    file = open(result_file_name, \"r\")\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    # confusion matrix\n",
    "    # .... true class: N, R, S\n",
    "    predicted_true = [[0, 0, 0],  # N - Predicted class\n",
    "                      [0, 0, 0],  # R - Predicted class\n",
    "                      [0, 0, 0]]  # S - Predicted class\n",
    "\n",
    "    for line in lines:\n",
    "        tweet_id, label, neutral, racist, sexism = line.strip().split(\",\")\n",
    "        predicted_class = prediction(float(neutral), float(racist), float(sexism))\n",
    "        predicted_true[predicted_class][int(label)] += 1\n",
    "\n",
    "    file = open(confusion_matrix_file_name, 'w')\n",
    "    for result_line in predicted_true:\n",
    "        file.write(\",\".join([str(result) for result in result_line]) + '\\n')\n",
    "    file.close()\n",
    "\n",
    "    return predicted_true\n",
    "\n",
    "\n",
    "def calculate_precision_recall_f1score(confusion_matrix: list, score_file_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    calculate precision, recall and f1 score\n",
    "    :param confusion_matrix: confusion matrix\n",
    "    :param score_file_name: file name to save scores\n",
    "    :return: {precision, recall, f1 score}\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    classes = ['N', 'R', 'S']\n",
    "    file = open(score_file_name, 'w')\n",
    "\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            precision = round(confusion_matrix[i][i] / sum(confusion_matrix[i]), 4)\n",
    "        except ZeroDivisionError:\n",
    "            precision = \"INFINITE\"\n",
    "\n",
    "        try:\n",
    "            recall = round(confusion_matrix[i][i] / sum([confusion_matrix[j][i] for j in range(3)]), 4)\n",
    "        except ZeroDivisionError:\n",
    "            recall = \"INFINITE\"\n",
    "\n",
    "        if precision != \"INFINITE\" and recall != \"INFINITE\":\n",
    "            try:\n",
    "                f1score = round((2 * precision * recall) / (precision + recall), 4)\n",
    "            except ZeroDivisionError:\n",
    "                f1score = \"NaN\"\n",
    "        else:\n",
    "            f1score = \"NaN\"\n",
    "\n",
    "        scores[classes[i]] = {'precision': precision, 'recall': recall, 'f1score': f1score}\n",
    "        file.write(\"%s: {precision:%s, recall:%s, f1score:%s}\\n\" % (classes[i], precision, recall, f1score))\n",
    "\n",
    "    file.close()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(levelname)s %(asctime)s: %(message)s', level=logging.INFO)\n",
    "directory = get_last_results_folder()\n",
    "logging.info(\"Validating on %s\" % directory)\n",
    "\n",
    "for i in range(5):  # here 5 is the number of folds\n",
    "    matrix = build_confusion_matrix(\"%s/test_set_predicted_output_%d.txt\" % (directory, i),\n",
    "                                    \"%s/confusion_matrix_%d.txt\" % (directory, i))\n",
    "    calculate_precision_recall_f1score(matrix, \"%s/scores_%d.txt\" % (directory, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
